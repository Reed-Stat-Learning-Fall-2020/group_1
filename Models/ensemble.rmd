---
title: "stacks"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
# loading packages

library(tidyverse)
library(tidymodels)
library(stacks)
library(janitor)
library(corrr)

```

```{r}
# loading data

data_raw <- read_csv("data/Final Mega Summary.csv")

data <-
  data_raw %>%
  select(-`ΔERA`,
         -`ΔSalary`) %>%
  mutate(salary_t1 = log(salary_t1)) %>%
  filter(ERA_t1 < 7.00) %>%
  filter(luck_adj_ERA < 7.00)

```


```{r}
data %>%
  filter(salary_t1 > 14 & salary_t1 < 15) %>%
  View()
```



## Era

```{r}
# test/train splits

set.seed(321)

data_split <- initial_split(data)
data_train <- training(data_split)
data_test <- testing(data_split)

# k-fold CV

set.seed(345)

folds <- vfold_cv(data_train, v = 5)
```

```{r}
# setting up a recipe

baseball_rec <- 
  recipe(ERA_t1 ~., data = data_train) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_zv(all_predictors(), -all_outcomes()) %>%
  update_role(Pitcher, new_role = "Id") %>%
  step_corr(all_numeric(), -all_outcomes(), threshold = 0.75) 

# workflow

baseball_wf <-
  workflow() %>%
  add_recipe(baseball_rec)

# rmse metric
metric <- metric_set(rmse)

```

```{r}

ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()

```

```{r}
# lasso model

lasso_spec <-
  linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

# add to wf

lasso_wf <-
  baseball_wf %>%
  add_model(lasso_spec)

# lambda grid

lambda_grid <-
  grid_regular(penalty(),
               levels = 50)

# k-fold CV

set.seed(875)
lasso_res <- 
  tune_grid(
    lasso_wf,
    resamples = folds,
    metrics = metric,
    control = ctrl_grid,
    grid = lambda_grid
  )

```


```{r}
# ridge spec

ridge_spec <- 
  linear_reg(penalty = tune(),
             mixture = 0) %>%
  set_engine("glmnet")

  
# add it to a workflow
ridge_wf <- 
  baseball_wf %>%
  add_model(ridge_spec)

# tune deg_free and fit to the 5-fold cv
set.seed(123)
ridge_res <- 
  tune_grid(
    ridge_wf,
    resamples = folds,
    metrics = metric,
    control = ctrl_grid,
    grid = lambda_grid
  )
```

```{r}
# random Forest spec

rf_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
  ) %>%
  set_mode("regression") %>%
  set_engine("ranger")

rf_wf <-
  baseball_wf %>%
  add_model(rf_spec)

rf_grid <- grid_regular(
  mtry(range = c(1,6)),
  min_n(range = c(2,8)),
  levels = 5
  )

set.seed(453)
randf_res <- tune_grid(
  rf_wf,
  resamples = folds,
  grid = rf_grid,
  metrics = metric,
  control = ctrl_grid
)
```



```{r}
# create data stack

baseball_d_stack <- 
  stacks() %>%
    add_candidates(lasso_res) %>%
    add_candidates(randf_res) %>%
    add_candidates(ridge_res)

```


```{r}
# blending predictions

base_stack <- 
  baseball_d_stack %>%
  blend_predictions()
```


```{r}
# fitting model

base_stack <-
  base_stack %>%
  fit_members()

```


```{r}
data_test <- 
  data_test %>%
  bind_cols(predict(base_stack, .))

```


```{r}
data_test %>%
  ggplot() +
  aes(
    x = ERA_t1, 
    y = .pred
  ) +
  geom_point() + 
  coord_obs_pred()
```

```{r}
rmse(data_test, truth = ERA_t1, estimate = .pred)
rsq(data_test, truth = ERA_t1, estimate = .pred)
```


## Salary

```{r}
data_s <-
  data_raw %>%
  select(-`ΔERA`,
         -`ΔSalary`) %>%
  filter(salary_t1 > 600000) %>%
  mutate(salary_t1 = log(salary_t1)) 
  
# test/train splits

set.seed(321)

data_split_s <- initial_split(data_s)
data_train_s <- training(data_split_s)
data_test_s <- testing(data_split_s)

# k-fold CV

set.seed(345)

folds_s <- vfold_cv(data_train_s, v = 5)
```

```{r}
# setting up a recipe

baseball_rec_s <- 
  recipe(salary_t1 ~., data = data_train_s) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_zv(all_predictors(), -all_outcomes()) %>%
  update_role(Pitcher, new_role = "Id") %>%
  step_corr(all_numeric(), -all_outcomes(), threshold = 0.75) 

# workflow

baseball_wf_s <-
  workflow() %>%
  add_recipe(baseball_rec_s)

# rmse metric
metric_s <- metric_set(rmse)

```

```{r}

ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()

```

```{r}
lm_mod <- 
  linear_reg() %>%
  set_engine("lm")

lm_wf <- 
  baseball_wf_s %>% 
  add_model(lm_mod)

lm_res <-
  lm_wf %>%
  fit_resamples(
    resamples = folds_s,
    control = ctrl_res
  )
```


```{r}
set.seed(76)
# lasso model

lasso_spec_s <-
  linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

# add to wf

lasso_wf_s <-
  baseball_wf_s %>%
  add_model(lasso_spec_s)

# lambda grid

lambda_grid_s <-
  grid_regular(penalty(),
               levels = 50)

# k-fold CV

set.seed(875)
lasso_res_s <- 
  tune_grid(
    lasso_wf_s,
    resamples = folds_s,
    metrics = metric_s,
    control = ctrl_grid,
    grid = lambda_grid_s
  )

```



```{r}
set.seed(12)
# random Forest spec

rf_spec_s <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
  ) %>%
  set_mode("regression") %>%
  set_engine("ranger")

rf_wf_s <-
  baseball_wf_s %>%
  add_model(rf_spec_s)

rf_grid_s <- grid_regular(
  mtry(range = c(1,6)),
  min_n(range = c(2,8)),
  levels = 5
  )

set.seed(453)
randf_res_s <- tune_grid(
  rf_wf_s,
  resamples = folds_s,
  grid = rf_grid_s,
  metrics = metric_s,
  control = ctrl_grid
)
```


```{r}
# create data stack

baseball_d_stack_s <- 
  stacks() %>%
    add_candidates(lasso_res_s) %>%
    add_candidates(randf_res_s) %>%
    add_candidates(lm_res)

```


```{r}
# blending predictions

base_stack_s <- 
  baseball_d_stack_s %>%
  blend_predictions()
```


```{r}
# fitting model

base_stack_s <-
  base_stack_s %>%
  fit_members()

```


```{r}
data_test_s <- 
  data_test_s %>%
  bind_cols(predict(base_stack_s, .))

```


We can see that our ensemble model performs fabulously except for one point in the top left hand corner of the graph. That observations corresponds to Jeremy Hellickson who signed a 1 year contract in 2017 worth 17.2 million dollars and then was traded to a minor league team the next year. This leads to a salary drop of around 15 million dollars which is certainly an anomaly. Since we don't have a variable that indicates being sent to the minors, we will drop this observation and see how our model performs without it.


```{r}
data_test_s %>%
  ggplot() +
  aes(
    x = salary_t1, 
    y = .pred
  ) +
  geom_point() + 
  coord_obs_pred()
```

```{r}
rmse(data_test_s, truth = salary_t1, estimate = .pred)
# 0.2209
rsq(data_test_s, truth = salary_t1, estimate = .pred)
# 0.776
```


Now our rsq is 0.829 and our mse is 0.184 which is a large improvement



```{r}
data_s <-
  data_raw %>%
  select(-`ΔERA`,
         -`ΔSalary`) %>%
  filter(salary_t1 > 600000) %>%
  mutate(salary_t1 = log(salary_t1)) %>%
  filter(Pitcher != "Jeremy Hellickson")
  
# test/train splits

set.seed(321)

data_split_s <- initial_split(data_s)
data_train_s <- training(data_split_s)
data_test_s <- testing(data_split_s)

# k-fold CV

set.seed(345)

folds_s <- vfold_cv(data_train_s, v = 5)
```

```{r}
# setting up a recipe

baseball_rec_s <- 
  recipe(salary_t1 ~., data = data_train_s) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>%
  step_zv(all_predictors(), -all_outcomes()) %>%
  update_role(Pitcher, new_role = "Id") %>%
  step_corr(all_numeric(), -all_outcomes(), threshold = 0.75) 

# workflow

baseball_wf_s <-
  workflow() %>%
  add_recipe(baseball_rec_s)

# rmse metric
metric_s <- metric_set(rmse)

```

```{r}

ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()

```

```{r}
lm_mod <- 
  linear_reg() %>%
  set_engine("lm")

lm_wf <- 
  baseball_wf_s %>% 
  add_model(lm_mod)

lm_res <-
  lm_wf %>%
  fit_resamples(
    resamples = folds_s,
    control = ctrl_res
  )
```


```{r}
set.seed(76)
# lasso model

lasso_spec_s <-
  linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

# add to wf

lasso_wf_s <-
  baseball_wf_s %>%
  add_model(lasso_spec_s)

# lambda grid

lambda_grid_s <-
  grid_regular(penalty(),
               levels = 50)

# k-fold CV

set.seed(875)
lasso_res_s <- 
  tune_grid(
    lasso_wf_s,
    resamples = folds_s,
    metrics = metric_s,
    control = ctrl_grid,
    grid = lambda_grid_s
  )

```



```{r}
set.seed(12)
# random Forest spec

rf_spec_s <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
  ) %>%
  set_mode("regression") %>%
  set_engine("ranger")

rf_wf_s <-
  baseball_wf_s %>%
  add_model(rf_spec_s)

rf_grid_s <- grid_regular(
  mtry(range = c(1,6)),
  min_n(range = c(2,8)),
  levels = 5
  )

set.seed(453)
randf_res_s <- tune_grid(
  rf_wf_s,
  resamples = folds_s,
  grid = rf_grid_s,
  metrics = metric_s,
  control = ctrl_grid
)
```


```{r}
# create data stack

baseball_d_stack_s <- 
  stacks() %>%
    add_candidates(lasso_res_s) %>%
    add_candidates(randf_res_s) %>%
    add_candidates(lm_res)

```


```{r}
# blending predictions

base_stack_s <- 
  baseball_d_stack_s %>%
  blend_predictions()
```


```{r}
# fitting model

base_stack_s <-
  base_stack_s %>%
  fit_members()

```


```{r}
data_test_s <- 
  data_test_s %>%
  bind_cols(predict(base_stack_s, .))

```


```{r}
data_test_s %>%
  ggplot() +
  aes(
    x = salary_t1, 
    y = .pred
  ) +
  geom_point() + 
  coord_obs_pred() +
  geom_abline(slope = 1, intercept = 0, color = "midnightblue", alpha = 0.5, size = 2)

```

```{r}
rmse(data_test_s, truth = salary_t1, estimate = .pred)
# 0.1814
rsq(data_test_s, truth = salary_t1, estimate = .pred)
# 0.829
```

```{r}
autoplot(base_stack_s, type = "weights")
```

```{r}
autoplot(base_stack_s)
```

```{r}
write_csv(data_test_s, "ensemblepreds.csv")
```

