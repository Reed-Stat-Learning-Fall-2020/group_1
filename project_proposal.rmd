---
title: "Project Proposal"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Since the sport’s inception in the nineteenth century, baseball has remained a fascination of statisticians and data scientists. More recently, the advent of sabermetrics and Statcast technology has propelled the mathematical study of baseball to new heights, with the ubiquity and accessibility of baseball metrics encouraging more and more professional baseball organizations to adopt an increasingly analytical approach.

Traditionally, these analytics have been entirely results-driven. That is, player’s abilities are assessed strictly on the tangible outcomes of their individual performances. To some extent, this makes sense. Results are easy to measure and ultimately determine whether teams win or lose. That being said, these outcomes are also subject to an extensive amount of randomness and “luck”. However, using the modeling techniques explored in this class, it is possible to assess player performance not based on actual outcomes, but rather on an aggregation of predicted outcomes determined by a set of relevant statistical parameters. Ultimately, models like these could be the next frontier in sports analytics.

For our project, we wish to explore a new method of pitcher performance evaluation using advanced pitch tracking data. Specifically, we aim to determine the predicted outcome of a given pitch based on a number of technical measurements of that pitch. These predicted outcomes can be both continuous (e.g. xBAA or xwOBAA) or discrete (e.g. PA result), depending on the desired response. Consequently, we can build both regression or classification models.

Statcast data will allow us to utilize both categorical as well as quantitative variables in our model as certain important predictors, such as pitch type, are categorical (e.g. fastball, curveball, changeup, etc.), while others, such as exit velocity or spin rate, are quantitative (measured in miles per hour or revolutions per minute respectively). We are trying to focus on variables that the pitcher can control, so we exclude certain batter-related variables such as exit velocity of the hit ball or the angle at which the ball is launched. Specifically, possible predictors include accuracy (which will be derived from the X and Y coordinates of the ball as it crosses the plate), velocity of the pitch, spin rate, pitch type, release extension (how far away from the plate the ball is released), vertical and horizontal movement of the ball in flight, and other possible statcast variables. We will then perform data exploration and subset selection to determine if every single predictor is correlated with or necessary for predicting hitting outcome.

Our main candidate for the data set for this project comes from Baseball Savant’s “Statcast” [https://baseballsavant.mlb.com/statcast_search]. Inside of Statcast we can search for a particular time frame, select the variables we want, and then download all of it as a csv. It’s really simple and the range of predictors available is enormous giving us a lot of options to consider.

The utility of such a statistic lies in the pragmatic value it could provide for baseball front offices. Here, it must be noted that a great deal of variability inheres within most sports, including baseball. However, by using past pitch data, we are able to assemble a dataset with a larger sample size than a single pitcher will experience within a season. This larger sample size can, hopefully, aid us in separating out the noise and artifacts in order to elucidate certain trends. If our model is able to predict the outcome of a pitch with high enough accuracy, it can provide insight into the true value of a pitcher after separating out some of the variability and noise normally found season-based statistics.

For example, according to baseball reference, in 2018, the average starting pitcher threw 88 pitches a game. Assuming that a starting pitcher plays in 12 games a season, this means that the total number of pitches for a starting pitcher in a season is around 1000. Such a sample size could be vulnerable to stochastic variability. For example, a strong performance could be overshadowed by lucky hits from the batter or random fielding mistakes from the defense. By fitting our model to a larger database of past pitches, we can hopefully provide a more accurate prediction of a pitcher’s true value than their season statistics would suggest. This could be valuable in identifying pitchers who are more valuable than their statistics suggest, who were simply victims of bad luck in a smallish sample size, as well as pitchers who are less valuable than their statistics would suggest and simply had a lucky season.

In addition to prediction, the model could also be used to perform inference on what makes a successful, difficult-to-hit pitch. For example, if we used a parametric model, by comparing the coefficients of various factors, one could determine which attributes of a pitch are most important in preventing a hit.

The obstacle that we foresee in data acquisition and analysis have to do with the size of the data set we’ll be working with. Since the number of observations quickly gets into the hundreds of thousands in just a couple of months, we’ll have to be strategic about how we choose the subset of pitch data that we want to use. Moreover, with a data set of this size we’ll have to be careful with any heavy computational work that we do.

Another potential obstacle is dividing our data into training and test sets. Specifically, if fielding or batting patterns have changed over time, then we will have to consider dividing our data up based on date in order to fit our model to data which more accurately reflects the distribution of data that it will be tested on. 
